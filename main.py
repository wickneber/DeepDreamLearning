# my implementation of deep dream, for learning purposes
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import numpy as np
import os
from collections import namedtuple
import cv2
import imageio as io
import argparse
import sys

'''
Basic feature extractor of the pretrained ResNet50 
'''


class ResNet50FeatureExtractor(nn.Module):
    def __init__(self, to_extract_from):
        super().__init__()
        self.network = to_extract_from.eval()

        for param in self.network.parameters():
            param.requires_grad = False

        self.features = nn.Sequential(*list(self.network.children()))
        self.base_layer = nn.Sequential()

        for i in range(4):
            self.base_layer.add_module(str(i), self.features[i])

        self.layer1 = self.features[4]
        self.layer2 = self.features[5]
        self.layer3 = self.features[6]
        self.layer4 = self.features[7]
        self.layer5 = nn.Sequential(*[self.features[8], self.features[9]])
        self.layer_names = ["base_layer", "layer1", "layer2", "layer3", "layer4"]

    def forward(self, x):

        exposed_layers = namedtuple("Resnet50Layers", self.layer_names)

        out = self.base_layer(x)
        base_activ = out

        out = self.layer1(out)
        layer_1_activ = out

        out = self.layer2(out)
        layer_2_activ = out

        out = self.layer3(out)
        layer_3_activ = out

        out = self.layer4(out)
        layer_4_activ = out

        #print(out.shape)
        #out = self.layer5(out)
        #layer_5_activ = out

        return exposed_layers(base_activ, layer_1_activ, layer_2_activ, layer_3_activ, layer_4_activ)


def preprocess_image(image_path, crop_fn=None):
    """
    Gets an image path, reads the image, preprocesses it, and returns its tensor equivalent
    :param image_path: The path to read the image from
    :return: A tensor version of the preprocessed image
    """

    image = cv2.imread(image_path)

    # If there is a dimension given
    original_size = image.shape

    if crop_fn:
        crop_from, crop_to = crop_fn(original_size)

        image = image[crop_from[0]:crop_from[1], crop_to[0]:crop_to[1]]

        image = cv2.resize(image, (original_size[1], original_size[0]), interpolation=cv2.INTER_CUBIC)

    # Convert the value from BGR to RGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = image.astype(np.float32)
    image /= 255.0
    return image


def create_pics(file_path, save_file_path, frames=30, iterations=30, lr=0.01, crop_fn=None):
    resNet = ResNet50FeatureExtractor(models.resnet50(pretrained=True))
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    resNet.to(device)
    image = preprocess_image(file_path, crop_fn=crop_fn)

    for frame in range(frames):
        print("Generating Frame : {}".format(frame+1))
        image = transforms.ToTensor()(image).to(device).unsqueeze(0)
        image.requires_grad = True
        resNet(image)

        for i in range(iterations):
            out = resNet(image)
            activation = out.layer3
            activation.backward(activation)
            image_tensor_grad = image.grad.data
            #smooth_grads = cv2.blur(image_tensor_grad, (5, 5))
            smooth_grads = image_tensor_grad / (torch.std(image_tensor_grad) + .01)
            image.data += lr * smooth_grads
            image.grad.data.zero_()

        img = np.moveaxis(image.to('cpu').detach().numpy()[0], 0, 2)
        img = (np.clip(img, 0., 1.) * 255).astype(np.uint8)
        filepath = '{}/{}.jpg'.format(save_file_path, frame)
        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Change the image back into BGR format for writing
        cv2.imwrite(filepath, img)
        image = preprocess_image(filepath, crop_fn=crop_fn)


def clear_directory(filepath: str) -> None:
    for root_dir, dir, files in os.walk(filepath):
        for file in files:
            os.remove('{}/{}'.format(filepath, file))


def generate_gif(picture_path, save_path, duration: float = 1):
    '''
    Given the pictures generated by deep dream, create a gif of it
    :param picture_path: The path of the pictures to generate the gif of
    :param save_path: The location to save the generated gif
    :param duration: The time between each picture in the gif
    :return: None
    '''
    images = []
    for directory, _, files in os.walk(picture_path):
        files.sort(key=lambda x: int(x.split('.')[0]))
        for file in files:
            images.append(io.imread(directory+"/"+file))
    io.mimsave(save_path, images, duration=duration)
    print('Gif saved at {}'.format(save_path))


# TODO Gotta refine the cropping formula and think about it a little more
def generate_crop_shape(x: int, y: int, image_shape: (int, int), zoom_factor=0.9):
    '''
    Given the x, y coordinate to zoom into for the deep dream gif, generate its new shape.
    :param zoom_factor: The percentage of the original image to zoom into.
    :param image_shape: The original size of the image given.
    :param x: The x coordinate to zoom into.
    :param y: The y coordinate to zoom into.
    :return: The new bounds of which to crop the picture.
    '''
    center = (float(x/image_shape[0]), float(y/image_shape[1]))  # The location of the desired center in percentages
    bounding_width = image_shape[0] * zoom_factor
    bounding_height = image_shape[1] * zoom_factor
    print(center)
    print("Bounding width: {}".format(bounding_width))
    print("Bounding height: {}".format(bounding_height))
    # TODO get the new shape and whatnot and return the new value
    new_shape = [((x-(bounding_width/2)), (center[0] + (bounding_width/2)))
                 ,((center[1] - (bounding_height / 2), center[1] + (bounding_height / 2)))]
    # [(From Width, To Width), (From Height, To Height)]
    print(new_shape)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description="Deep Dream code based off the ResNet50 architecture.")
    parser.add_argument('-f', '--save_location', type=str)
    parser.add_argument('-p', '--picture_location', type=str, help='The filepath of the picture to dream.')
    parser.add_argument('-nf', '--num_frames', type=int,
                        help='The number of frames for the gif generation')
    parser.add_argument('-ni', '--num_iterations', type=int,
                        help='The number of iterations each frame should get for the deep dreaming.')
    parser.add_argument('-lr', '--learning_rate', type=float,
                        help='The learning rate for the gradient ascent.')
    arguments = parser.parse_args()
    
    save_location = arguments.save_location
    picture_location = arguments.picture_location
    num_frames = arguments.num_frames
    num_iterations = arguments.num_iterations
    learning_rate = arguments.learning_rate

    if not picture_location:
        print("Please enter in a filepath to the picture to deep dream on.\n"
              "If you are having difficulty entering arguments, you can rerun the program with the -h flag.")
        sys.exit(0)

    clear_directory('deep_dream_pics')
    if not save_location:
        save_location = 'DeepDream.gif'
    crop_fn = lambda x: [(int(x[0]*.1), int(x[0]*.95)), (int(x[1]*.05), int(x[1]*.95))]
    #crop_fn = lambda x: [(0, int(x[0]*.9)), (0, int(x[1]*.9))]
    create_pics(picture_location, 'deep_dream_pics', frames=num_frames, iterations=num_iterations, lr=learning_rate,
                crop_fn=crop_fn)

    print("Generating gif...")
    generate_gif('deep_dream_pics', save_location, duration=.5)
